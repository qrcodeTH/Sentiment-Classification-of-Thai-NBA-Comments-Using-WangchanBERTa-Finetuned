{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9097284,"sourceType":"datasetVersion","datasetId":5490289}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset, DatasetDict\n\n# Load your Excel dataset\nfile_path = \"/kaggle/input/nba-thaicomments-dataset/NBA_Comment_Data.xlsx\"\ndf = pd.read_excel(file_path)\n\n# Assuming 'text' column contains the comments and 'label' column contains the labels\ndf = df.rename(columns={'data': 'text', 'label': 'label'})\n\n# Map labels to integers if necessary\nlabel_map = {'P': 0, 'Neu': 1, 'Neg': 2}\ndf['label'] = df['label'].map(label_map)\n\n# Convert the DataFrame to a Dataset\ndataset = Dataset.from_pandas(df)\n\n# Split the dataset into train, validation, and test sets\ndataset_split = dataset.train_test_split(test_size=0.2, seed=42)\ntest_dataset = dataset_split['test']\n\n# Further split the training set into train and validation sets\ntrain_val_dataset = dataset_split['train'].train_test_split(test_size=0.1, seed=42)  # 10% of train for validation\n\n# Combine the splits into a DatasetDict\ndataset_dict = DatasetDict({\n    'train': train_val_dataset['train'],\n    'validation': train_val_dataset['test'],\n    'test': test_dataset\n})\n\n# Save the DatasetDict\ndataset_dict.save_to_disk('/kaggle/working/nba_comments_dataset')","metadata":{"execution":{"iopub.status.busy":"2024-08-05T03:56:18.117228Z","iopub.execute_input":"2024-08-05T03:56:18.117564Z","iopub.status.idle":"2024-08-05T03:56:20.842796Z","shell.execute_reply.started":"2024-08-05T03:56:18.117533Z","shell.execute_reply":"2024-08-05T03:56:20.841941Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/360 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37d44a6749bb4ec38dabf0dcda8965e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/40 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18e7fd8721ca4b4192b3e849c416c13b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bab2cb1bec3c4ba985c8440557b3efb9"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"poom-sci/WangchanBERTa-finetuned-sentiment\")","metadata":{"execution":{"iopub.status.busy":"2024-08-05T03:56:20.844535Z","iopub.execute_input":"2024-08-05T03:56:20.844962Z","iopub.status.idle":"2024-08-05T03:56:28.554088Z","shell.execute_reply.started":"2024-08-05T03:56:20.844936Z","shell.execute_reply":"2024-08-05T03:56:28.553282Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/491 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25a34dd0149d4d58840b72d858797cac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/905k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf0291df0d0a44ec8c932f2768ff3abd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.38M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f2a60f93383413a955be9774ab507e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/305 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95bc9c077f384f7a9776406944314e93"}},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T03:56:28.555072Z","iopub.execute_input":"2024-08-05T03:56:28.555505Z","iopub.status.idle":"2024-08-05T03:56:28.559988Z","shell.execute_reply.started":"2024-08-05T03:56:28.555481Z","shell.execute_reply":"2024-08-05T03:56:28.558934Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"tokenized = dataset_dict.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T03:56:28.561076Z","iopub.execute_input":"2024-08-05T03:56:28.561343Z","iopub.status.idle":"2024-08-05T03:56:28.680700Z","shell.execute_reply.started":"2024-08-05T03:56:28.561321Z","shell.execute_reply":"2024-08-05T03:56:28.679811Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/360 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd7cad2cd7f24d399493646a275f3549"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/40 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e84de672d1a4263a39227134f556c9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d7bfa0f326e42ed9612784956ee043b"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T03:56:28.682612Z","iopub.execute_input":"2024-08-05T03:56:28.682882Z","iopub.status.idle":"2024-08-05T03:56:40.119620Z","shell.execute_reply.started":"2024-08-05T03:56:28.682858Z","shell.execute_reply":"2024-08-05T03:56:40.118821Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2024-08-05 03:56:31.104329: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-05 03:56:31.104459: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-05 03:56:31.236980: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"poom-sci/WangchanBERTa-finetuned-sentiment\")","metadata":{"execution":{"iopub.status.busy":"2024-08-05T03:56:40.120696Z","iopub.execute_input":"2024-08-05T03:56:40.121279Z","iopub.status.idle":"2024-08-05T03:56:47.995241Z","shell.execute_reply.started":"2024-08-05T03:56:40.121253Z","shell.execute_reply":"2024-08-05T03:56:47.994390Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/965 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49437c91682d464f8002e7a675e2f941"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/421M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be4dd56c4b7c47bb97314617661f9f2d"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./results\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=100,\n    weight_decay=0.01,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized[\"train\"],\n    eval_dataset=tokenized[\"validation\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T03:56:47.996557Z","iopub.execute_input":"2024-08-05T03:56:47.996917Z","iopub.status.idle":"2024-08-05T03:59:23.780795Z","shell.execute_reply.started":"2024-08-05T03:56:47.996867Z","shell.execute_reply":"2024-08-05T03:59:23.779925Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240805_035707-vu22zhxq</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/thanaphum04571/huggingface/runs/vu22zhxq' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/thanaphum04571/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/thanaphum04571/huggingface' target=\"_blank\">https://wandb.ai/thanaphum04571/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/thanaphum04571/huggingface/runs/vu22zhxq' target=\"_blank\">https://wandb.ai/thanaphum04571/huggingface/runs/vu22zhxq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1150' max='1150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1150/1150 01:57, Epoch 50/50]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.136600</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.003700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1150, training_loss=0.06113788480344026, metrics={'train_runtime': 153.6195, 'train_samples_per_second': 117.173, 'train_steps_per_second': 7.486, 'total_flos': 425795621679792.0, 'train_loss': 0.06113788480344026, 'epoch': 50.0})"},"metadata":{}}]},{"cell_type":"code","source":"# Save the model and tokenizer\nmodel.save_pretrained(\"/kaggle/working/saved_model\")\ntokenizer.save_pretrained(\"/kaggle/working/saved_model\")","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:07:29.145610Z","iopub.execute_input":"2024-08-05T04:07:29.146470Z","iopub.status.idle":"2024-08-05T04:07:29.979728Z","shell.execute_reply.started":"2024-08-05T04:07:29.146437Z","shell.execute_reply":"2024-08-05T04:07:29.978611Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/saved_model/tokenizer_config.json',\n '/kaggle/working/saved_model/special_tokens_map.json',\n '/kaggle/working/saved_model/sentencepiece.bpe.model',\n '/kaggle/working/saved_model/added_tokens.json',\n '/kaggle/working/saved_model/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, AutoTokenizer\n\n# Load the saved model and tokenizer\nmodel = AutoModelForSequenceClassification.from_pretrained(\"/kaggle/working/saved_model\")\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/working/saved_model\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:08:27.056060Z","iopub.execute_input":"2024-08-05T04:08:27.057171Z","iopub.status.idle":"2024-08-05T04:08:27.361470Z","shell.execute_reply.started":"2024-08-05T04:08:27.057128Z","shell.execute_reply":"2024-08-05T04:08:27.360304Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Load the test dataset\ntest_dataset = dataset_dict[\"test\"]\n\n# Tokenize the test dataset\ndef preprocess_test_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\")\n\ntokenized_test = test_dataset.map(preprocess_test_function, batched=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:08:42.839249Z","iopub.execute_input":"2024-08-05T04:08:42.839965Z","iopub.status.idle":"2024-08-05T04:08:42.888109Z","shell.execute_reply.started":"2024-08-05T04:08:42.839933Z","shell.execute_reply":"2024-08-05T04:08:42.887185Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5318ac45a8d54174b32668191be15beb"}},"metadata":{}},{"name":"stderr","text":"Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\nAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import Trainer\n\n# Initialize Trainer with the loaded model\ntrainer = Trainer(\n    model=model,\n    tokenizer=tokenizer,\n    data_collator=data_collator\n)\n\n# Evaluate the model\neval_results = trainer.evaluate(eval_dataset=tokenized_test)\nprint(f\"Evaluation results: {eval_results}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:08:55.850804Z","iopub.execute_input":"2024-08-05T04:08:55.851175Z","iopub.status.idle":"2024-08-05T04:08:56.447524Z","shell.execute_reply.started":"2024-08-05T04:08:55.851144Z","shell.execute_reply":"2024-08-05T04:08:56.446617Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Evaluation results: {'eval_loss': 2.070568561553955, 'eval_runtime': 0.1986, 'eval_samples_per_second': 503.573, 'eval_steps_per_second': 65.464}\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# Extract predictions\npredictions = trainer.predict(tokenized_test)\npredicted_labels = predictions.predictions.argmax(axis=-1)\ntrue_labels = tokenized_test[\"label\"]\n\n# Calculate accuracy\naccuracy = accuracy_score(true_labels, predicted_labels)\nprint(f\"Accuracy: {accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:09:02.601385Z","iopub.execute_input":"2024-08-05T04:09:02.601754Z","iopub.status.idle":"2024-08-05T04:09:02.852391Z","shell.execute_reply.started":"2024-08-05T04:09:02.601725Z","shell.execute_reply":"2024-08-05T04:09:02.851565Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Accuracy: 0.7400\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}